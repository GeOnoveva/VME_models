---
author: "Havforskningsinstituttet"
date: "`r format(Sys.Date())`"
output: word_document
bibliography: references.bib
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
# libraries
library(ranger)
library(spm)
library(yardstick)
library(readxl)
library(dplyr)
library(tinytex)
library(knitr)
library(Ckmeans.1d.dp)
library(terra)

# paths
Data <- "G:/R_projects/VH_MarVid/Data"
outpath <- "G:/R_projects/VH_MarVid/Results"
savepath <- "G:/R_projects/VH_MarVid/Intermediate_objects"

# quantiles
quantiles = c((1-.682)/2, 0.5, 1-(1-.682)/2)

# taxonary
taxonary <- read_xlsx(file.path(Data,"Taxonary.xlsx"), sheet = 1) # needs to be closed

# vme and indicators
vme <- "Hard bottom sponge aggregations"
remove=""
#remove <- c("Mycale lingua", "Phakellia sp.", "Axinellidae", "Axinella infundibuliformis")
indicators <- taxonary$Reference_List[which(taxonary$VME_Burgos_etal_2020==vme)]
#indicators <- indicators[-which(indicators%in%remove)]

# model
m <- readRDS(file.path(outpath,paste(vme,"minus", paste(substr(remove, 1,7), collapse=", "), "model.rda" )))

# re-generate v_test and v_train
v <- read.csv(file.path(savepath, paste(vme, "minus", paste(substr(remove, 1,7), collapse=", "), "v.csv", collapse=" ")))
v <- v %>% 
      mutate_at(vars(  landscape, sedclass, seddan, sedmil    ), factor)
data_split <- read.csv(file.path(outpath, paste(vme,"minus", paste(substr(remove, 1,7), collapse=", "), "data split.csv")))
v_train <- v %>% left_join(filter(data_split, data_split$set=="train")) %>% filter(!is.na(set))
v_test <- v %>% left_join(filter(data_split, data_split$set=="test")) %>% filter(!is.na(set))

# predict with m3
vme.qrf2 <- predict(m,  v_test,
type="quantiles", quantiles=quantiles)$predictions
v_test$vme.qrf2pr = vme.qrf2[,2]
v_test$vme.qrf2var = (vme.qrf2[,3]-vme.qrf2[,1])/2

# test m3
predicted <- v_test$vme.qrf2pr
observed <- v_test %>%
dplyr::select(vmeind_density)
vecv <- vecv(pull(observed),pull(data.frame(unlist(predicted))))
ccc <- ccc_vec(pull(observed),predicted)

# threshold
distribution <- rast(file.path(savepath, paste(vme,"minus", paste(remove, collapse=", "), "pred.tif")))
errorr <- rast(file.path(savepath, paste(vme,"minus", paste(remove, collapse=", "), "pred var.tif")))
distribution[errorr>quantile(values(errorr, na.rm=TRUE), 0.9)]<-NA
val <- values(distribution, na.rm=TRUE) %>% data.frame %>% pull
th<- Ckmeans.1d.dp(val, k=2)$centers[2]
```

---
title: "Produktark: `r vme`"
---


# Description
This vector dataset shows the "hot spots" (high predicted density areas) for the Vulnerable Marine Ecosystem referred to as:
```{r echo=FALSE, message=FALSE, warning=FALSE}
vme
```

The definition for this VME followed @buhl2019vulnerable and @burgos2020predicting. Therefore, this VME is defined by occurrence of the following indicators:
```{r echo=FALSE, message=FALSE, warning=FALSE}
indicators
```

# Goal and usage
The goal is to highlight specific areas which may be subject to special management requirements due to the expected high density of VME indicators, i.e., the potential presence of a VME (cite Baco Taylor?).

# Owner and contact information
Havforskningsinstituttet
Fagekspert: Genoveva Gonzalez Mirelis: <genoveva@hi.no>
Datateknisk: Kjell Bakkeplass: <kjell.bakkeplass@hi.no>

# Resolution/Scale
```{r echo=FALSE, message=FALSE, warning=FALSE}
mna<-8000*8000
paste("1:", sprintf("%.0f",mna*2000))
```

# Coverage
The coverage of this dataset is the entire MAREANO area as of 2020. It is the same as the biotope map which was published in 2022, shown here: (mareano biotoper dekningskart). The available number of video lines for this area is 2228, which amount to 6031 200-m samples.

# Sources and method
This polygon dataset was generated in two main steps: (1) a model of VME indicator density was trained and subsequently used for predicting density of all VME indicators throughout the entire area (2) the continuous surface thus generated was binned into two classes using the univariate version of the kmeans algorithm. A brief overview is provided here.

## Modelling
Training data was extracted from MarVid, summarized as follows:
```{r echo=FALSE, message=FALSE, warning=FALSE}
summ_tr <- data.frame("Training"=dim(v_train)[1],
                      "Testing"=dim(v_test)[1])
#kable(
  summ_tr
#  )
```

The variable was distributed as follows
```{r echo=FALSE, message=FALSE, warning=FALSE}
hist(v$vmeind_density)
```

with model
```{r echo=FALSE, message=FALSE, warning=FALSE}
m
```

with evaluation
```{r echo=FALSE, message=FALSE, warning=FALSE}
vecv
```
and
```{r echo=FALSE, message=FALSE, warning=FALSE}
ccc
```

## Vectorization
The threshold used was:
```{r}
th
```
# Updating

# Deliverable
## Format
## Projection
## Restrictions

## Links

## References

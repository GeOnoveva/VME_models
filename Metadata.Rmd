---
author: "Havforskningsinstituttet"
date: "`r format(Sys.Date())`"
output: word_document
bibliography: references.bib
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
# libraries
library(ranger)
library(spm)
library(yardstick)
library(readxl)
library(dplyr)
library(tinytex)
library(knitr)
library(Ckmeans.1d.dp)
library(terra)

# paths
Data <- "G:/R_projects/VH_MarVid/Data"
outpath <- "G:/R_projects/VH_MarVid/Results"
savepath <- "G:/R_projects/VH_MarVid/Intermediate_objects"

# quantiles
quantiles = c((1-.682)/2, 0.5, 1-(1-.682)/2)

# taxonary
taxonary <- read_xlsx(file.path(Data,"Taxonary.xlsx"), sheet = 1) # needs to be closed

# vme and indicators
vme <- "Soft bottom sponge aggregations (boreal ostur)"
remove="nothing"
#remove <- c("Mycale lingua", "Phakellia sp.", "Axinellidae", "Axinella infundibuliformis")
indicators <- taxonary$Reference_List[which(taxonary$VME_BuhlMortensen_etal_2023==vme)]
#indicators <- indicators[-which(indicators%in%remove)]

# model
name <-"m2"
m <- readRDS(file = file.path(outpath, paste(paste(vme,"minus", paste(substr(remove, 1,7), collapse=", ")),
                                             paste0(name, ".rda"))))

# re-generate v_test and v_train
v <- read.csv(file.path(savepath, paste(vme, "minus", paste(substr(remove, 1,7), collapse=", "), "v.csv", collapse=" ")))
v <- v %>% 
      mutate_at(vars(  landscape, sedclass, seddan, sedmil    ), factor)
#data_split <- read.csv(file.path(outpath, paste(vme,"minus", paste(substr(remove, 1,7), collapse=", "), "data split.csv")))
#v_train <- v %>% left_join(filter(data_split, data_split$set=="train")) %>% filter(!is.na(set))
#v_test <- v %>% left_join(filter(data_split, data_split$set=="test")) %>% filter(!is.na(set))

# predict with m3
# vme.qrf2 <- predict(m,  v_test,
# type="quantiles", quantiles=quantiles)$predictions
# v_test$vme.qrf2pr = vme.qrf2[,2]
# v_test$vme.qrf2var = (vme.qrf2[,3]-vme.qrf2[,1])/2
# 
# # test m3
# predicted <- v_test$vme.qrf2pr
# observed <- v_test %>%
# dplyr::select(vmeind_density)
# vecv <- vecv(pull(observed),pull(data.frame(unlist(predicted))))
# ccc <- ccc_vec(pull(observed),predicted)

# threshold
distribution <- rast(file.path(file.path(outpath, name), paste(vme,"minus", paste(remove, collapse=", "), "pred.tif")))
error <- rast(file.path(file.path(outpath, name), paste(vme,"minus", paste(remove, collapse=", "), "pred var.tif")))
val <- values(distribution, na.rm=TRUE) %>% data.frame %>% pull
th<-Ckmeans.1d.dp(val, k=2)$centers[2]
val <- values(error, na.rm=TRUE) %>% data.frame %>% pull
thr<-Ckmeans.1d.dp(val, k=2)$centers[2]

# data summary
sp<-indicators
e <- read.csv(file.path(savepath, "pred_data/e.csv"))
sample_info <- read.csv(file.path(Data,"sample_info.csv"))
sample_info <- sample_info %>% rename(video.line=VL, section=SampID2, mean.latitude=y_coord, mean.longitude=x_coord) %>%
  dplyr::select(video.line, section, mean.latitude, mean.longitude, SampID)
e <- cbind(e,sample_info)
threshold <- vector(mode = "numeric",
                   length = length(sp))
for (i in 1:length(sp)){
  threshold[i] <- (data %>% dplyr::filter(taxon==sp[i]) %>% dplyr::pull(density) %>% sort %>% quantile(., c(.01, .05)))[1]
}
thresholdt <- data.frame(sp=sp, threshold=as.numeric(threshold))
data <- read.csv(file.path(Data,"species_densities.csv"))
data <- data %>% rename(taxon=clean_taxonomy, density = density_n100m2) %>% dplyr::select(SampID, taxon, density)
data_extract <- data %>% filter(taxon%in%indicators) %>% left_join(e, by = join_by(SampID == section))
data_extract_merged <-merge(data_extract,thresholdt,by.x="taxon",by.y="sp",all.x=TRUE)
s <- summarize(group_by(data_extract_merged, taxon), mean=mean(density, na.rm=TRUE),
                                                     median=median(density, na.rm=TRUE),
                                                     max=max(density, na.rm=TRUE),
                                                     count=length(density))
```

---
title: "Produktark: `r vme`"
---

# Description
This vector dataset shows the predicted density hot spots for the Vulnerable Marine Ecosystem (VME) known as
```{r echo=FALSE, message=FALSE, warning=FALSE}
vme
```

The definition for this VME followed @buhl2019vulnerable and @burgos2020predicting. Therefore, this VME is defined by occurrence of the following indicators:
```{r echo=FALSE, message=FALSE, warning=FALSE}
indicators
```

# Goal and usage
The goal of this dataset is to highlight specific areas which may be subject to special management requirements due to the expected high density of VME indicators, i.e., the potential presence of a VME (@bacoTaylor2023).

# Owner and contact information
Havforskningsinstituttet
Fagekspert: Genoveva Gonzalez Mirelis: <genoveva@hi.no>
Datateknisk: Kjell Bakkeplass: <kjell.bakkeplass@hi.no>

# Resolution/Scale
```{r echo=FALSE, message=FALSE, warning=FALSE}
mna<-8000*8000
paste("1:", sprintf("%.0f",mna*2000))
```

# Coverage
The coverage of this dataset is the entire MAREANO area as of 2020. It is the same as the biotope map which was published in 2022, shown here: (mareano biotoper dekningskart). The available number of video lines for this area is 2228, which amount to 6031 200-m samples.

# Sources and method
This polygon dataset was generated in two main steps: (1) a model was trained and subsequently used for predicting density of VME indicators throughout the entire coverage area (2) the continuous surface thus generated was binned into two classes using a univariate kmeans algorithm. A brief overview is provided here.

## Modelling
Training data was extracted from MarVid, summarized as follows:
```{r}
kable(s)
```

For modelling we used Quantile Regression Forests as applied in @hengl2018, which we used to predict the mean VME indicator density. We also calculated the top and bottom bounds for the expected prediction range and then subtracted pixels where the error was high/range was broad (define better).

Predictor variables were the same as were used in the biotope model published in 2022 ^[https://mareano.no/en/topics/habitats/general-biotope-map/mareano-general-biotopes--2022-update-technical-summary/predicted-distribution-of-general-biotopes-raster-map].

The final model included `r length(selvar)` variables. And the number of trees was `r m$num.trees`. The model was internally evaluated by using the "Out of Bag" procedure and it resulted in the following R^2 value:
```{r}
m$r.squared
```


## Vectorization
The model output is a raster layer (continuous variable). In order to create a polygon, this raster is reclassified into two classes: low and high. The threshold between the two classes was calculated using a univariate kmeans algorithm. This algorithm classifies values into k classes (in this case two) of similar means. The center for the high cluster was used as a threshold, which was:
```{r}
th
thr
```

# Updating
The dataset will be updated according to the MAREANO Activity Plan.

# Deliverable
## Format
Shapefile (?)

## Projection
WGS84 UTM 33N

## Restrictions
License

## Links
The workflow can be downloaded/cloned from the following github repository:
https://github.com/GeOnoveva/VME_models.git

Information about environmental predictors can be found here:
https://mareano.no/en/topics/habitats/general-biotope-map/mareano-general-biotopes--2022-update-technical-summary/predicted-distribution-of-general-biotopes-raster-map


## References

---
title: "R Notebook"
output: html_notebook
---

# Intro

inputs: (1) resp (in intermediate folder) (2) sample info
workflow: 
outputs: cleaned up resp (only samples withe metadata) and get local variability of vme density

# Libraries
```{r}
library(dplyr)
library(rgdal)
library(raster)
library(qdapTools)
library(RPostgreSQL)
```


# Inputs
```{r}
resp <- read.csv(file.path(savepath, paste(vme,"resp.csv", collapse=" ")))

# set vme (again!)
vme <- "Hard bottom sponge aggregations"
```

## Get sample info
### If Marvid runing use this:
```{python}
import requests

API_URL = "http://marvid-staging.hi.no:8092/query/video_lines"
OUTPUL_FILEPATH = "C:\\Users\\genoveva\\Downloads\\marvid_sections.csv"
DELIMITER = ","
CSV_HEADER = DELIMITER.join(["video line", "section", "mean latitude", "mean longitude"])

api_response = requests.get(API_URL).json() 
output_strings = [CSV_HEADER] 
for vl_number in sorted(api_response.keys()):
    vl = api_response[vl_number]
    for section in sorted(vl["sections"]):
        mean_lat = str(vl["sections"][section]["mean_lat"])
        mean_lon = str(vl["sections"][section]["mean_lon"])
        output_strings.append(DELIMITER.join([vl_number, section, mean_lat, mean_lon]))

with open(OUTPUL_FILEPATH, "w") as output_file:
    output_file.write("\n".join(output_strings))n
```

### If not, use this:
```{r}
sample_info <- read.csv(file.path(Data, "sample_info.csv"))
sample_info <- sample_info %>% rename(video.line=VL, section=SampID2, mean.latitude=y_coord, mean.longitude=x_coord) %>%
  dplyr::select(video.line, section, mean.latitude, mean.longitude, SampID)
# sample_info <- sample_info %>% makesampid # only needed when we switch to using marvid sections
```


# Aggregate to whole video line and calculate sd
```{r}
respw <- resp %>% mutate(video.line=sub("_.*", "", SampID))

respw <- respw %>% group_by(video.line) %>%
  summarize(mean_rich = mean(tot_rich), mean_dens = mean(tot_dens), sd_dens = sd(tot_dens))

head(respw)
```

# Make spatial object
```{r}
resp_spat1 <- resp %>% mutate(mean_long=as.numeric(pull(
                                dplyr::filter(data.frame(lookup(SampID,dplyr::select(sample_info, c(SampID, mean.longitude)), missing = NULL)), 
                                                      !duplicated(data.frame(qdapTools::lookup(SampID,dplyr::select(sample_info, c(SampID, mean.longitude)), missing = NULL)))
                                                       ))),
                             mean_lat=as.numeric(pull(
                               dplyr::filter(data.frame(lookup(SampID,dplyr::select(sample_info, c(SampID, mean.latitude)), missing = NULL)), 
                                                      !duplicated(data.frame(qdapTools::lookup(SampID,dplyr::select(sample_info, c(SampID, mean.latitude)), missing = NULL)))
                                                       )))) %>%
            filter(!is.na(mean_long))

resp_spat <- SpatialPointsDataFrame(dplyr::select(resp_spat1, c(mean_long, mean_lat)), dplyr::select(resp_spat1, c(SampID,tot_rich, tot_dens, vmeind_density)))  
                      #%>% utmize

writeOGR(resp_spat, savepath, paste(vme, "resp_spat"), driver = "ESRI Shapefile", overwrite_layer = TRUE)

# make resp have the same number of rows as resp_spat:

resp <- resp %>% filter(SampID%in%resp_spat@data$SampID)
head(resp)
```

# Get coordinates of video lines
```{r}
library(RPostgreSQL)
library(rgdal)

postgres_driver <- dbDriver("PostgreSQL")
postgres_conn <- dbConnect(postgres_driver,
                           dbname = "marbunn",
                           host = "postgres.hi.no",
                           port = 5432,
                           user = "marbunn_read",
                           password = "Ecac7adgb!")
tab_station <- dbGetQuery(postgres_conn, "select * from tab_station")
tab_station <- tab_station[which(tab_station$equipment==2),]

```

# Make spatial object, video line level
```{r}

resp_spat1 <- respw %>% mutate(mean_long=as.numeric(pull(
  dplyr::filter(data.frame(lookup(video.line,dplyr::select(tab_station, c(sample_no, lon_mid_dec)), missing = NULL))))),
  mean_lat=as.numeric(pull(
    dplyr::filter(data.frame(lookup(video.line,dplyr::select(tab_station, c(sample_no, lat_mid_dec)), missing = NULL)))))) %>%
  dplyr::filter(!is.na(mean_long)) %>% rename(vmeind_density = mean_dens)

coords <- coordinates(dplyr::select(resp_spat1, c(mean_long, mean_lat)))

resp_spat_vl <- SpatialPointsDataFrame(coords, dplyr::select(resp_spat1, c(video.line,mean_rich, vmeind_density, sd_dens))) %>%
                       utmize

writeOGR(resp_spat_vl, savepath, paste(vme, "resp_spat_vl"), driver = "ESRI Shapefile", overwrite_layer = TRUE)

# make resp have the same number of rows as resp_spat:

respw <- respw %>% filter(video.line%in%resp_spat@data$video.line)
```


# Save outputs
```{r}
rm(resp_spat1)
write.csv(resp, file.path(savepath, paste(vme,"resp new.csv", collapse=" ")))
write.csv(respw, file.path(savepath, "st_dev_vme_dens.csv"), row.names = FALSE)
```

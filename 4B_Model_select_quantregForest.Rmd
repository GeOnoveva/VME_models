---
title: "R Notebook"
output: html_notebook
---

inputs: v, resp_spat (whole video line level), pred (as spatial pixels)

# Libraries etc
```{r}
library(quantregForest)
library(tidyverse)
library(rgdal)
library(caret)
library(spm)
library(DescTools)

quantiles = c((1-.682)/2, 0.5, 1-(1-.682)/2)
```

# Inputs
```{r}
# get v (read)
v <- read.csv(file.path(savepath, "v.csv"))
# str(v)

v <- v %>% 
      mutate_at(vars(  landscape, sedclass, seddan, sedmil    ), factor)
```

# More inputs: resp spat at station level
```{r}
resp_spat_vl <- readRDS(file.path(savepath, "resp_Spat_vl.rds"))
```

# More inputs: pred
```{r}
#load(file.path(savepath,"1_Predictors_out.RData"))
pred.pix <- readRDS(file.path(savepath,"pred.rds"))
pred.pix1 <- subset(pred.pix, complete.cases(pred.pix@data))
```

# select environmental variables
```{r}
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(v[,8:121], v[,4], sizes=c(1:113), rfeControl=control)
# chosen features
selvar <- predictors(results)
selvar
```

# add spatial variables
```{r}
resp.dist0 <-buffer.dist(resp_spat_vl["vmeind_density"], 
                                 pred.pix[1], as.factor(1:nrow(resp_spat_vl))) 

ov.resp = over(resp_spat["vmeind_density"], resp.dist0)
all_names <- paste(c(names(resp.dist0), selvar), collapse="+")
fmla0 <- as.formula(paste("vmeind_density ~ ", 
                           all_names))
fmla0
ov.resp <- over(resp_spat["vmeind_density"], pred.pix[1:2])
sw.rm = do.call(cbind, list(resp_spat@data["vmeind_density"], ov.resp
                            , ov.resp
                            ))
```

# new v
```{r}
v <- v %>% left_join(sw.rm) %>% filter(complete.cases(.))
```

# fine tune mtry parameter
```{r}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(1)
tunegrid <- expand.grid(.mtry=c(1:30))
rf_gridsearch <- train(fmla0, data=v, method="qrf", metric="Rsquared", tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
mtry=rf_gridsearch$bestTune
```

# train new model
without case weights
```{r}
m1 <- ranger(formula = fmla0,
             data = v,
             mtry=mtry, 
             min.node.size=2,
             sample.fraction=0.9930754, 
             num.trees=250,
             importance = "impurity",
             seed=1,
             quantreg=TRUE,
             respect.unordered.factors = "partition"
             )
m1
```

with case weights
```{r}
m2 <- ranger(formula = fmla0,
             data = v,
             mtry=mtry, 
             min.node.size=2,
             sample.fraction=0.9930754, 
             num.trees=250,
             importance = "impurity",
             seed=1,
             quantreg=TRUE,
             respect.unordered.factors = "partition",
             case.weights = as.integer(1/(v$sd_dens^2))
             )
m2
```

# Split data for model testing
split the data into two partitions where (1) video lines are kept together and (2) the testing data is biased towards intermediate to high-density observations
```{r}
n<-3 # n classes to stratify the response variable into
keep=0.25 # proportion of observations in the low density class that will be treated normally
p=0.5 # overall proportion of the dataset that should be used for testing the model

v <- v %>% filter(complete.cases(.))


# video.line is single column. extract or lookup from sample info
video.line <- as.character(lookup(v$SampID, dplyr::select(sample_info, section, video.line), sample_info$video.line))

v_test <- stratisplit(v, n, keep, p, as.factor(video.line))[[1]]
v_train <- stratisplit(v, n, keep, p, as.factor(video.line))[[2]]

rbind(hist(log(v_train$vmeind_density)), hist(log(v_test$vmeind_density)))

```

# test model
```{r}
m3 <- ranger(formula = fmla0,
             data = v_train,
             mtry=mtry, 
             min.node.size=2,
             sample.fraction=0.9930754, 
             num.trees=250,
             importance = "impurity",
             seed=1,
             quantreg=TRUE,
             respect.unordered.factors = "partition",
             case.weights = as.integer(1/(v$sd_dens^2))
             )
m3
```

# variance explained by cross-validation (from spm library)
```{r}
vme.qrf2 <- predict(m3,  v_test, 
                     type="quantiles", quantiles=quantiles)$predictions
## now more computational...
v_test$vme.qrf2pr = vme.qrf2[,2]
## s.d. of the prediction error:
v_test$vme.qrf2var = (vme.qrf2[,3]-vme.qrf2[,1])/2

predicted <- v_test$vme.qrf2pr
observed <- v_test %>%
  dplyr::select(vmeind_density)

vecv <- vecv(pull(observed),pull(data.frame(unlist(predicted)))) # variance explained by cross-validation, conservative estimate to report
vecv
```

# concordance correlation coefficient
```{r}
ccc <- CCC(predicted, pull(observed))
ccc$rho.c
```


---
title: "R Notebook"
output: html_notebook
---

inputs: v, resp_spat (whole video line level), pred

# Libraries etc
```{r}
library(quantregForest)
library(tidyverse)
library(rgdal)
library(caret)
library(spm)

quantiles = c((1-.682)/2, 0.5, 1-(1-.682)/2)
## color legend:
leg = c("#0000ff", "#0028d7", "#0050af", "#007986", "#00a15e", "#00ca35", 
        "#00f20d", "#1aff00", "#43ff00", "#6bff00", "#94ff00", "#bcff00", 
        "#e5ff00", "#fff200", "#ffca00", "#ffa100", "#ff7900", "#ff5000", "#ff2800", "#ff0000")
```

# Inputs
```{r}
# get v (read)
v <- read.csv(file.path(savepath, "v.csv"))
# str(v)

v <- v %>% 
      mutate_at(vars(  landscape, sedclass, seddan, sedmil    ), factor)
```

# More inputs: resp spat at station level
```{r}
resp_spat_vl <- readRDS(file.path(savepath, "resp_Spat_vl.rds"))
```

# More inputs: pred
comes with a bunch of other objects because loading whole workspace
```{r}
#load(file.path(savepath,"1_Predictors_out.RData"))
pred.pix <- readRDS(file.path(savepath,"pred.rds"))
pred.pix1 <- subset(pred.pix, complete.cases(pred.pix@data))
```

# select environmental variables
```{r}
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(v[,8:121], v[,4], sizes=c(1:113), rfeControl=control)
# chosen features
selvar <- predictors(results)
selvar
```

# add spatial variables
```{r}
resp.dist0 <-buffer.dist(resp_spat_vl["vmeind_density"], 
                                 pred.pix[1], as.factor(1:nrow(resp_spat_vl))) 

ov.resp = over(resp_spat["vmeind_density"], resp.dist0)
all_names <- paste(c(names(resp.dist0), selvar), collapse="+")
fmla0 <- as.formula(paste("vmeind_density ~ ", 
                           all_names))
fmla0
ov.resp <- over(resp_spat["vmeind_density"], pred.pix[1:2])
sw.rm = do.call(cbind, list(resp_spat@data["vmeind_density"], ov.resp
                            , ov.resp
                            ))
```

# new v
```{r}
v <- left_join(v, sw.rm)
```

# fine tune RF parameters
```{r}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(1)
tunegrid <- expand.grid(.mtry=c(1:30))
rf_gridsearch <- train(fmla0, data=v, method="qrf", metric="Rsquared", tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
```

# train final model
```{r}
mtry=rf_gridsearch$bestTune
m1 <- ranger(fmla0, v[complete.cases(v),], mtry=mtry, 
                  min.node.size=2, sample.fraction=0.9930754, 
                  num.trees=150, importance = "impurity", seed=1, quantreg=TRUE)
m1
```

# test model
Needs v_train and v_test from Notebook 4
```{r}
m2<-ranger(fmla0, v_train, mtry=mtry,  min.node.size=2, sample.fraction=0.9930754, num.trees=500, # these parameters need to have been fined-tuned on a previous step
                   importance="impurity", seed=1, quantreg= TRUE)
m2
```

```{r}
vme.qrf2 <- predict(m2, cbind(
  #swiss.dist0@data, 
  v_test), 
                     type="quantiles", quantiles=quantiles)$predictions
## now more computational...
v_test$vme.qrf2pr = vme.qrf2[,2]
## s.d. of the prediction error:
v_test$vme.qrf2var = (vme.qrf2[,3]-vme.qrf2[,1])/2

predicted <- v_test$vme.qrf2pr
observed <- v_test %>%
  dplyr::select(vmeind_density)

vecv <- vecv(pull(observed),pull(data.frame(unlist(predicted)))) # variance explained by cross-validation, conservative estimate to report
vecv
```


